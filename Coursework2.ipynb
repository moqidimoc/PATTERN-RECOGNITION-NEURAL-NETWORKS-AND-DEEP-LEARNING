{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'C:\\\\Users\\\\Asus\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a simple program to apply the Widrow-Hoff Learning Algorithm\n",
    "def widrow(n, data, epochs, a, b, eta): #eta is the learning rate\n",
    "    for e in range(epochs): #for the indicated epochs\n",
    "        last_a = a\n",
    "        for i in range(n): #for all datapoints (misclassified and correctly classified)\n",
    "            last_a = a\n",
    "            # First, we multiply the initial gradient descent vector (a) by the respective datapoint (y)\n",
    "            new_a = eta*(b[i] - np.dot(a, np.array(data.iloc[i])))*data.iloc[i]\n",
    "            \n",
    "            # Now we update a with its new value\n",
    "            a = a + np.array(new_a)\n",
    "            # Before passing to the next point, let's print the last value of a and the new value of a, along with the iteration\n",
    "            # number\n",
    "            #print(\"Iteration #{}: \\naTyK = {}\".format(e*n+i+1, np.dot(a, np.array(data.iloc[i]))))\n",
    "            #print('last a: {}\\nnew a: {}'.format(np.array(last_a), np.array(a)))\n",
    "            \n",
    "            # 2nd version\n",
    "            print(\"iteration #{}: aTyK = {} // a = {}\".format(n*e+i+1,np.dot(last_a, np.array(data.iloc[i])), a))\n",
    "            \n",
    "        # And before exiting the first loop, we print the new values after the first epoch\n",
    "        print('Epoch #{}: \\nlast a: {}\\nnew a: {}'.format(e+1, np.array(last_a), np.array(a)))\n",
    "        \n",
    "    return a        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration #1: aTyK = -1.5 // a = [-0.8  5.  -1. ]\n",
      "iteration #2: aTyK = 4.2 // a = [-1.24  4.56 -1.  ]\n",
      "iteration #3: aTyK = 6.879999999999999 // a = [-2.216  2.608 -1.976]\n",
      "iteration #4: aTyK = 4.192 // a = [-1.7776  2.608  -1.5376]\n",
      "iteration #5: aTyK = 2.2447999999999997 // a = [-1.72864  2.65696 -1.43968]\n",
      "Epoch #1: \n",
      "last a: [-1.7776  2.608  -1.5376]\n",
      "new a: [-1.72864  2.65696 -1.43968]\n",
      "iteration #6: aTyK = -1.7286399999999997 // a = [-0.982912  2.65696  -1.43968 ]\n",
      "iteration #7: aTyK = 1.674048 // a = [-0.9177216  2.7221504 -1.43968  ]\n",
      "iteration #8: aTyK = 3.0868991999999995 // a = [-1.13510144  2.28739072 -1.65705984]\n",
      "iteration #9: aTyK = 2.7921612799999997 // a = [-0.97666918  2.28739072 -1.49862758]\n",
      "iteration #10: aTyK = 1.686533632 // a = [-1.03936246  2.22469745 -1.62401413]\n",
      "Epoch #2: \n",
      "last a: [-0.97666918  2.28739072 -1.49862758]\n",
      "new a: [-1.03936246  2.22469745 -1.62401413]\n",
      "[-1.03936246  2.22469745 -1.62401413]\n"
     ]
    }
   ],
   "source": [
    "# Slide example\n",
    "b = np.array([2, 2, 2, 2, 2, 2])\n",
    "y = pd.DataFrame([[1, 0, 0], [1, 1, 0], [1, 2, 1], [-1, 0, -1], [-1, -1, -2]])\n",
    "a = np.array([-1.5, 5, -1])\n",
    "\n",
    "# And here we estimate the new vector\n",
    "w = widrow(n=5, data=y, epochs=2, a=a, b=b, eta=0.2)\n",
    "print(w) # It should be [-1.0394, 2.2247, -1.624]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration #1: aTyK = 1 // a = [1. 0. 0.]\n",
      "iteration #2: aTyK = 1.0 // a = [1. 0. 0.]\n",
      "iteration #3: aTyK = 1.0 // a = [1. 0. 0.]\n",
      "iteration #4: aTyK = -1.0 // a = [ 0.8  0.6 -0.2]\n",
      "iteration #5: aTyK = 0.20000000000000012 // a = [ 0.72  0.76 -0.12]\n",
      "iteration #6: aTyK = 1.32 // a = [ 0.752  0.664 -0.184]\n",
      "Epoch #1: \n",
      "last a: [ 0.72  0.76 -0.12]\n",
      "new a: [ 0.752  0.664 -0.184]\n",
      "iteration #7: aTyK = 0.384 // a = [ 0.8136  0.664  -0.0608]\n",
      "iteration #8: aTyK = 1.3559999999999999 // a = [ 0.778   0.6284 -0.132 ]\n",
      "iteration #9: aTyK = 1.9028 // a = [ 0.68772  0.44784 -0.22228]\n",
      "iteration #10: aTyK = 0.8780799999999997 // a = [ 0.675528  0.484416 -0.234472]\n",
      "iteration #11: aTyK = 0.05883199999999972 // a = [ 0.5814112  0.6726496 -0.1403552]\n",
      "iteration #12: aTyK = 1.1558271999999998 // a = [ 0.59699392  0.62590144 -0.17152064]\n",
      "Epoch #2: \n",
      "last a: [ 0.5814112  0.6726496 -0.1403552]\n",
      "new a: [ 0.59699392  0.62590144 -0.17152064]\n",
      "aT: [ 0.59699392  0.62590144 -0.17152064]\n"
     ]
    }
   ],
   "source": [
    "# Labsheet example\n",
    "b = np.array([1, 1, 1, 1, 1, 1])\n",
    "y = pd.DataFrame([[1, 0, 2], [1, 1, 2], [1, 2, 1], [-1, 3, -1], [-1, 2, 1], [-1, 3, 2]])\n",
    "a = np.array([1, 0, 0])\n",
    "\n",
    "# We estimate the new vector\n",
    "w = widrow(n=6, data=y, epochs=2, a=a, b=b, eta=0.1)\n",
    "print(\"aT: {}\".format(w)) # It should be [0.597, 0.6259, 0.1715]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration #1: aTyK = 1 // a = [1. 0. 0.]\n",
      "iteration #2: aTyK = 1.0 // a = [1.15 0.15 0.3 ]\n",
      "iteration #3: aTyK = 1.75 // a = [ 1.025 -0.1    0.175]\n",
      "iteration #4: aTyK = -1.4999999999999998 // a = [ 0.625  1.1   -0.225]\n",
      "iteration #5: aTyK = 1.35 // a = [ 0.71  0.93 -0.31]\n",
      "iteration #6: aTyK = 1.46 // a = [ 0.756  0.792 -0.402]\n",
      "Epoch #1: \n",
      "last a: [ 0.71  0.93 -0.31]\n",
      "new a: [ 0.756  0.792 -0.402]\n",
      "iteration #7: aTyK = -0.04800000000000004 // a = [ 0.8608  0.792  -0.1924]\n",
      "iteration #8: aTyK = 1.268 // a = [0.984  0.9152 0.054 ]\n",
      "iteration #9: aTyK = 2.8684 // a = [ 0.74716  0.44152 -0.18284]\n",
      "iteration #10: aTyK = 0.7602399999999999 // a = [ 0.573184  0.963448 -0.356816]\n",
      "iteration #11: aTyK = 0.9968960000000002 // a = [ 0.6228736  0.8640688 -0.4065056]\n",
      "iteration #12: aTyK = 1.1563216 // a = [ 0.63850576  0.81717232 -0.43776992]\n",
      "Epoch #2: \n",
      "last a: [ 0.6228736  0.8640688 -0.4065056]\n",
      "new a: [ 0.63850576  0.81717232 -0.43776992]\n",
      "aT: [ 0.63850576  0.81717232 -0.43776992]\n"
     ]
    }
   ],
   "source": [
    "# Coursework 1 exercise 1\n",
    "b = np.array([1, 2.5, 0.5, 2.5, 0.5, 1])\n",
    "y = pd.DataFrame([[1, 0, 2], [1, 1, 2], [1, 2, 1], [-1, 3, -1], [-1, 2, 1], [-1, 3, 2]])\n",
    "a = np.array([1, 0, 0])\n",
    "\n",
    "# We estimate the new vector\n",
    "w = widrow(n=6, data=y, epochs=2, a=a, b=b, eta=0.1)\n",
    "print(\"aT: {}\".format(w)) # It should be [0.63850576, 0.81717232, -0.43776992]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4\n",
       "0    1  5.1  3.5  1.4  0.2\n",
       "1    1  4.9  3.0  1.4  0.2\n",
       "2    1  4.7  3.2  1.3  0.2\n",
       "3    1  4.6  3.1  1.5  0.2\n",
       "4    1  5.0  3.6  1.4  0.2\n",
       "..  ..  ...  ...  ...  ...\n",
       "145  1  6.7  3.0  5.2  2.3\n",
       "146  1  6.3  2.5  5.0  1.9\n",
       "147  1  6.5  3.0  5.2  2.0\n",
       "148  1  6.2  3.4  5.4  2.3\n",
       "149  1  5.9  3.0  5.1  1.8\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coursework 1 exercise 2\n",
    "\n",
    "# What we are going to do is apply the Widrow-Hoff Learning Algorithm to the Iris dataset, locating instances of class 0 (class \n",
    "# 0) and instances of class 1 and 2 (class 1)\n",
    "y = pd.DataFrame(iris.data) # We put the 150 data points (50 of class 0 and 100 of class 1)\n",
    "target = iris.target # We locate the 150 targets (0, 1 or 2) in this array\n",
    "\n",
    "# As the targets have 50 labels of class 0 (first 50 entries), and 100 labels of class 1, we'll concat a all-1s array to the\n",
    "# df y with the data points. We will later apply sample normalisation to correctly asses the target\n",
    "new_target = pd.DataFrame([1]*150)\n",
    "\n",
    "# Now we append this df to the data points to have the data\n",
    "data = pd.concat([new_target, y], axis=1)\n",
    "data.columns = [0, 1, 2, 3, 4]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-6.7</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>-2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-6.3</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>-5.4</td>\n",
       "      <td>-2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-5.1</td>\n",
       "      <td>-1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4\n",
       "0    1.0  5.1  3.5  1.4  0.2\n",
       "1    1.0  4.9  3.0  1.4  0.2\n",
       "2    1.0  4.7  3.2  1.3  0.2\n",
       "3    1.0  4.6  3.1  1.5  0.2\n",
       "4    1.0  5.0  3.6  1.4  0.2\n",
       "..   ...  ...  ...  ...  ...\n",
       "145 -1.0 -6.7 -3.0 -5.2 -2.3\n",
       "146 -1.0 -6.3 -2.5 -5.0 -1.9\n",
       "147 -1.0 -6.5 -3.0 -5.2 -2.0\n",
       "148 -1.0 -6.2 -3.4 -5.4 -2.3\n",
       "149 -1.0 -5.9 -3.0 -5.1 -1.8\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The last thing we need to do before applying the learning algorithm is to do sample normalisation to change all the signs of\n",
    "# our datapoints\n",
    "data.iloc[50:] = -data.iloc[50:] # We also change the target from 1 to -1 because we set all targets to 1\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration #1: aTyK = 0.8000000000000016 // a = [ 0.502  -1.4898  2.507  -0.4972 -0.4996]\n",
      "iteration #2: aTyK = -0.07302000000000053 // a = [ 0.5127302  -1.43722202  2.5391906  -0.48217772 -0.49745396]\n",
      "iteration #3: aTyK = 1.1568747980000005 // a = [ 0.51116145 -1.44459514  2.53417061 -0.48421709 -0.49776771]\n",
      "iteration #4: aTyK = 0.8960735282506018 // a = [ 0.51220072 -1.43981452  2.53739233 -0.4826582  -0.49755986]\n",
      "iteration #5: aTyK = 1.6725070604801262 // a = [ 0.50547565 -1.47343987  2.51318207 -0.49207329 -0.49890487]\n",
      "iteration #6: aTyK = 1.314223879650898 // a = [ 0.50233341 -1.49040796  2.50092734 -0.4974151  -0.50016177]\n",
      "iteration #7: aTyK = 1.303180081244971 // a = [ 0.49930161 -1.50435424  2.49061922 -0.50165962 -0.50107131]\n",
      "iteration #8: aTyK = 0.5929320370864462 // a = [ 0.50337229 -1.48400085  2.50445953 -0.4955536  -0.50025717]\n",
      "iteration #9: aTyK = 0.44287472324944055 // a = [ 0.50894354 -1.45948733  2.52061616 -0.48775385 -0.49914292]\n",
      "iteration #10: aTyK = 0.3898206437682461 // a = [ 0.51504533 -1.42958855  2.53953172 -0.47860116 -0.49853274]\n",
      "iteration #11: aTyK = 1.3739262772216954 // a = [ 0.51130607 -1.44978056  2.52569645 -0.48421005 -0.49928059]\n",
      "iteration #12: aTyK = 1.2651350911763481 // a = [ 0.50865472 -1.46250705  2.51668186 -0.48845221 -0.49981086]\n",
      "iteration #13: aTyK = 0.30485227241175483 // a = [ 0.5156062  -1.42913996  2.53753629 -0.47872015 -0.49911572]\n",
      "iteration #14: aTyK = 1.406409514198006 // a = [ 0.5115421  -1.44661557  2.525344   -0.48319065 -0.49952213]\n",
      "iteration #15: aTyK = 1.54281462350212 // a = [ 0.50611395 -1.47809881  2.50363142 -0.48970443 -0.50060775]\n",
      "iteration #16: aTyK = 2.1621292122961044 // a = [ 0.49449266 -1.54434018  2.45249773 -0.50713636 -0.50525627]\n",
      "iteration #17: aTyK = 0.8584170695660074 // a = [ 0.49590849 -1.5366947   2.45801947 -0.50529579 -0.50468994]\n",
      "iteration #18: aTyK = 0.40301256822625575 // a = [ 0.50187837 -1.50624834  2.47891403 -0.49693796 -0.50289898]\n",
      "iteration #19: aTyK = 0.3404718905859454 // a = [ 0.50847365 -1.46865524  2.5039761  -0.48572598 -0.50092039]\n",
      "iteration #20: aTyK = 1.6545759921057748 // a = [ 0.50192789 -1.50203862  2.47910221 -0.49554462 -0.50288412]\n",
      "iteration #21: aTyK = -0.12313581554723996 // a = [ 0.51315925 -1.44138928  2.51728883 -0.47645131 -0.50063785]\n",
      "iteration #22: aTyK = 1.5611104515424499 // a = [ 0.50754814 -1.47000592  2.49652774 -0.48486797 -0.50288229]\n",
      "iteration #23: aTyK = 2.147576363323683 // a = [ 0.49607238 -1.52279443  2.45521499 -0.49634373 -0.50517744]\n",
      "iteration #24: aTyK = -0.2643428081420538 // a = [ 0.50871581 -1.45831294  2.4969383  -0.47484991 -0.49885573]\n",
      "iteration #25: aTyK = 0.9964179315496606 // a = [ 0.50875163 -1.45814101  2.49706009 -0.47478185 -0.49884857]\n",
      "iteration #26: aTyK = -0.150193790630202 // a = [ 0.52025356 -1.40063132  2.53156591 -0.45637875 -0.49654818]\n",
      "iteration #27: aTyK = 1.1955958017988735 // a = [ 0.51829761 -1.41041111  2.52491565 -0.45950828 -0.49733056]\n",
      "iteration #28: aTyK = 1.232636096861519 // a = [ 0.51597125 -1.42250818  2.51677339 -0.46299782 -0.49779583]\n",
      "iteration #29: aTyK = 0.9282020903246666 // a = [ 0.51668922 -1.41877469  2.51921452 -0.46199265 -0.49765224]\n",
      "iteration #30: aTyK = 1.0712159334253917 // a = [ 0.51597706 -1.42212184  2.51693561 -0.46313211 -0.49779467]\n",
      "iteration #31: aTyK = 0.6517223039573556 // a = [ 0.51945984 -1.40540451  2.52773221 -0.45755966 -0.49709811]\n",
      "iteration #32: aTyK = 0.6393862696745609 // a = [ 0.52306598 -1.38593137  2.53999308 -0.45215046 -0.49565566]\n",
      "iteration #33: aTyK = 3.002403237096324 // a = [ 0.50304195 -1.49005634  2.45789455 -0.48218651 -0.49765806]\n",
      "iteration #34: aTyK = 1.8562964697479698 // a = [ 0.49447898 -1.53715264  2.4219301  -0.49417466 -0.49937066]\n",
      "iteration #35: aTyK = -0.37072178886856477 // a = [ 0.5081862  -1.46998728  2.46442247 -0.47361383 -0.49662921]\n",
      "iteration #36: aTyK = 0.3767392915819592 // a = [ 0.51441881 -1.43882424  2.48436681 -0.4661347  -0.49538269]\n",
      "iteration #37: aTyK = 0.5911176847025574 // a = [ 0.51850763 -1.41633571  2.4986777  -0.46081923 -0.49456493]\n",
      "iteration #38: aTyK = 1.879098923088831 // a = [ 0.50971664 -1.45941156  2.46703013 -0.47312662 -0.49544402]\n",
      "iteration #39: aTyK = 0.7752427720511692 // a = [ 0.51196421 -1.44952224  2.47377285 -0.47020477 -0.49499451]\n",
      "iteration #40: aTyK = 0.7259224105672217 // a = [ 0.51470499 -1.43554429  2.48309149 -0.46609361 -0.49444636]\n",
      "iteration #41: aTyK = 1.2735481770255657 // a = [ 0.51196951 -1.44922169  2.4735173  -0.46964973 -0.495267  ]\n",
      "iteration #42: aTyK = -1.0795630745036409 // a = [ 0.53276514 -1.35564136  2.52134725 -0.44261541 -0.48902831]\n",
      "iteration #43: aTyK = 1.9630486830988874 // a = [ 0.52313465 -1.3980155   2.4905297  -0.45513505 -0.49095441]\n",
      "iteration #44: aTyK = 1.2271223766526926 // a = [ 0.52086343 -1.40937162  2.48258041 -0.458769   -0.49231714]\n",
      "iteration #45: aTyK = 1.6982857833077185 // a = [ 0.51388057 -1.44498419  2.45604555 -0.47203643 -0.49511029]\n",
      "iteration #46: aTyK = 0.1367090131344879 // a = [ 0.52251348 -1.40354622  2.48194428 -0.45995036 -0.49252041]\n",
      "iteration #47: aTyK = 1.961391348094617 // a = [ 0.51289957 -1.45257718  2.44541141 -0.47533262 -0.49444319]\n",
      "iteration #48: aTyK = 0.8920067286287896 // a = [ 0.5139795  -1.44760949  2.4488672  -0.47382072 -0.49422721]\n",
      "iteration #49: aTyK = 1.0928812953045677 // a = [ 0.51305069 -1.4525322   2.44543059 -0.47521394 -0.49441297]\n",
      "iteration #50: aTyK = 0.5561285143526398 // a = [ 0.5174894  -1.43033863  2.46007835 -0.46899973 -0.49352523]\n",
      "iteration #51: aTyK = 4.517864352925849 // a = [ 0.55266804 -1.18408812  2.57265001 -0.30366011 -0.44427513]\n",
      "iteration #52: aTyK = 0.8258991069737567 // a = [ 0.55092704 -1.19523058  2.56707878 -0.31149465 -0.44688664]\n",
      "iteration #53: aTyK = 1.9348735018851624 // a = [ 0.56027577 -1.13072431  2.59605986 -0.26568585 -0.43286354]\n",
      "iteration #54: aTyK = 1.3132362496134276 // a = [ 0.56340813 -1.11349631  2.60326429 -0.2531564  -0.42879147]\n",
      "iteration #55: aTyK = 1.192884533462557 // a = [ 0.56533698 -1.10095882  2.60866506 -0.24428371 -0.4258982 ]\n",
      "iteration #56: aTyK = 0.05881048957424717 // a = [ 0.55592508 -1.15460662  2.58231175 -0.28663724 -0.43813366]\n",
      "iteration #57: aTyK = 0.24467673688984704 // a = [ 0.54837185 -1.20219199  2.55738608 -0.32213743 -0.45021883]\n",
      "iteration #58: aTyK = 0.717914647628354 // a = [ 0.545551   -1.21601417  2.55061603 -0.33144625 -0.45303969]\n",
      "iteration #59: aTyK = 2.196960359278858 // a = [ 0.5575206  -1.13701479  2.58532788 -0.27638607 -0.4374792 ]\n",
      "iteration #60: aTyK = 0.06494756169507898 // a = [ 0.54817008 -1.18563751  2.56008147 -0.31285312 -0.45056994]\n",
      "iteration #61: aTyK = 1.8054103958554588 // a = [ 0.55622418 -1.14536699  2.57618968 -0.28466375 -0.44251583]\n",
      "iteration #62: aTyK = 0.33223356014612015 // a = [ 0.54954652 -1.18476521  2.55615668 -0.31270994 -0.45253233]\n",
      "iteration #63: aTyK = 2.638872161278911 // a = [ 0.56593524 -1.08643288  2.59221187 -0.24715506 -0.43614361]\n",
      "iteration #64: aTyK = 0.31612074335407936 // a = [ 0.55909644 -1.12814952  2.57237937 -0.27929738 -0.44571792]\n",
      "iteration #65: aTyK = -0.11645545710574368 // a = [ 0.54793189 -1.19067102  2.54000216 -0.31948978 -0.46023184]\n",
      "iteration #66: aTyK = 1.605636856831591 // a = [ 0.55398826 -1.15009335  2.55877691 -0.29284176 -0.45175292]\n",
      "iteration #67: aTyK = 0.2056210927872577 // a = [ 0.54604447 -1.19457857  2.53494554 -0.32858881 -0.46366861]\n",
      "iteration #68: aTyK = 1.3490410130455208 // a = [ 0.54953488 -1.17433419  2.54436965 -0.31427813 -0.4601782 ]\n",
      "iteration #69: aTyK = 3.2382427618850143 // a = [ 0.57191731 -1.03556314  2.59361099 -0.2135572  -0.42660456]\n",
      "iteration #70: aTyK = 0.04534692018841824 // a = [ 0.56237078 -1.08902372  2.56974466 -0.25078867 -0.43710574]\n",
      "iteration #71: aTyK = -0.36973781604950595 // a = [ 0.5486734  -1.16983825  2.52591305 -0.31653609 -0.46176102]\n",
      "iteration #72: aTyK = 1.3812170363427212 // a = [ 0.55248557 -1.14658401  2.53658713 -0.30128741 -0.4568052 ]\n",
      "iteration #73: aTyK = 2.491041942078872 // a = [ 0.56739599 -1.05264836  2.57386318 -0.22822635 -0.43443957]\n",
      "iteration #74: aTyK = 0.2409334737020341 // a = [ 0.55980532 -1.09895142  2.55260931 -0.26390248 -0.44354837]\n",
      "iteration #75: aTyK = 0.7823103039735413 // a = [ 0.55762843 -1.11288356  2.54629631 -0.27326313 -0.44637833]\n",
      "iteration #76: aTyK = 0.9758016127192528 // a = [ 0.55738644 -1.11448066  2.54557036 -0.27432786 -0.44671711]\n",
      "iteration #77: aTyK = 1.8356627140669461 // a = [ 0.56574307 -1.05765559  2.56896892 -0.23421605 -0.43501783]\n",
      "iteration #78: aTyK = 0.7242532304550098 // a = [ 0.5629856  -1.07613063  2.56069651 -0.24800339 -0.43970553]\n",
      "iteration #79: aTyK = 0.24335181810086493 // a = [ 0.55541912 -1.12152952  2.53875372 -0.28205256 -0.45105525]\n",
      "iteration #80: aTyK = 0.6747786732852266 // a = [ 0.55216691 -1.14006713  2.53029796 -0.29343531 -0.45430746]\n",
      "iteration #81: aTyK = 1.2602795872425272 // a = [ 0.5547697  -1.12575176  2.53654467 -0.28354468 -0.45144439]\n",
      "iteration #82: aTyK = 1.0497174495698118 // a = [ 0.55526688 -1.1230173   2.53773789 -0.28170514 -0.45094721]\n",
      "iteration #83: aTyK = 0.746127819523223 // a = [ 0.55272815 -1.13774188  2.53088334 -0.29160615 -0.45399368]\n",
      "iteration #84: aTyK = 1.6539193728124726 // a = [ 0.55926735 -1.09850672  2.54853917 -0.25825626 -0.44353097]\n",
      "iteration #85: aTyK = -0.445498918539994 // a = [ 0.54481236 -1.17656366  2.5051742  -0.32330371 -0.46521345]\n",
      "iteration #86: aTyK = 0.19618557769130351 // a = [ 0.53677422 -1.22479253  2.47784451 -0.35947536 -0.47807448]\n",
      "iteration #87: aTyK = 2.39466367594426 // a = [ 0.55072085 -1.13135006  2.52107908 -0.29392617 -0.45715453]\n",
      "iteration #88: aTyK = 2.6658786808276753 // a = [ 0.56737964 -1.0263997   2.55939429 -0.22062751 -0.43549811]\n",
      "iteration #89: aTyK = -1.0270038476276655 // a = [ 0.5471096  -1.13991192  2.49858418 -0.30373467 -0.46184916]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration #90: aTyK = 1.291288084771959 // a = [ 0.55002248 -1.12389107  2.50586638 -0.29208314 -0.45806241]\n",
      "iteration #91: aTyK = 0.9509665691517322 // a = [ 0.54953215 -1.12658791  2.50459151 -0.29424061 -0.45865081]\n",
      "iteration #92: aTyK = 0.8044975595920807 // a = [ 0.54757712 -1.13851356  2.49872644 -0.30323373 -0.46138785]\n",
      "iteration #93: aTyK = 1.3257131262353763 // a = [ 0.55083425 -1.1196222   2.50719498 -0.2902052  -0.45747929]\n",
      "iteration #94: aTyK = 0.6958847564955448 // a = [ 0.5477931  -1.13482796  2.50020033 -0.300241   -0.46052044]\n",
      "iteration #95: aTyK = 0.916391402395603 // a = [ 0.54695702 -1.13951004  2.49794289 -0.30375257 -0.46160735]\n",
      "iteration #96: aTyK = 0.2841111541768564 // a = [ 0.53979813 -1.18031571  2.47646623 -0.3338199  -0.47019802]\n",
      "iteration #97: aTyK = 1.0195503413682951 // a = [ 0.53999363 -1.17920134  2.47703319 -0.33299878 -0.46994387]\n",
      "iteration #98: aTyK = 1.630480215037264 // a = [ 0.54629843 -1.14011157  2.49531711 -0.30588813 -0.46174762]\n",
      "iteration #99: aTyK = 0.4555645504861179 // a = [ 0.54085408 -1.16787777  2.48170623 -0.3222212  -0.46773641]\n",
      "iteration #100: aTyK = 1.0964360351084448 // a = [ 0.54181844 -1.16238092  2.48440644 -0.31826732 -0.46648274]\n",
      "iteration #101: aTyK = 1.6584508882526663 // a = [ 0.54840295 -1.12089851  2.50613532 -0.27876027 -0.45002147]\n",
      "iteration #102: aTyK = 1.462961230323045 // a = [ 0.55303256 -1.09404676  2.51863527 -0.25514924 -0.44122521]\n",
      "iteration #103: aTyK = 2.090747116296118 // a = [ 0.56394003 -1.01660372  2.55135768 -0.19079516 -0.41831952]\n",
      "iteration #104: aTyK = 0.2631541543897846 // a = [ 0.55657157 -1.06302501  2.52998915 -0.23205853 -0.43158274]\n",
      "iteration #105: aTyK = 1.058545016702734 // a = [ 0.55715702 -1.05921958  2.5317455  -0.22866292 -0.43029475]\n",
      "iteration #106: aTyK = 2.3104695206003383 // a = [ 0.57026172 -0.9596239   2.57105959 -0.14217193 -0.40277489]\n",
      "iteration #107: aTyK = -0.9712625924359157 // a = [ 0.55054909 -1.05621576  2.52177803 -0.23087875 -0.43628636]\n",
      "iteration #108: aTyK = 2.0865212605577828 // a = [ 0.5614143  -0.97689971  2.55328714 -0.16242791 -0.41672898]\n",
      "iteration #109: aTyK = 1.2927899289548463 // a = [ 0.5643422  -0.95728279  2.56060689 -0.14544609 -0.41145876]\n",
      "iteration #110: aTyK = -0.9742228945027467 // a = [ 0.54459997 -1.09942683  2.48953487 -0.26587369 -0.46081433]\n",
      "iteration #111: aTyK = 0.912747348693153 // a = [ 0.54372745 -1.10509826  2.48674278 -0.27032357 -0.46255938]\n",
      "iteration #112: aTyK = 2.1262736541010767 // a = [ 0.55499018 -1.03301674  2.51715217 -0.21063107 -0.44116018]\n",
      "iteration #113: aTyK = 1.0029744278465351 // a = [ 0.55501993 -1.03281448  2.5172414  -0.21046748 -0.44109772]\n",
      "iteration #114: aTyK = 0.9734519342123704 // a = [ 0.55475445 -1.03432772  2.5165777  -0.21179488 -0.44162868]\n",
      "iteration #115: aTyK = 0.5379914969569963 // a = [ 0.55013436 -1.06112421  2.50364146 -0.23535731 -0.45271688]\n",
      "iteration #116: aTyK = 0.5180505282140029 // a = [ 0.54531487 -1.09196898  2.48821908 -0.26090064 -0.46380172]\n",
      "iteration #117: aTyK = 1.3576228659779037 // a = [ 0.5488911  -1.06872349  2.49894777 -0.24123138 -0.45736451]\n",
      "iteration #118: aTyK = 0.806730460123676 // a = [ 0.5469584  -1.08360525  2.49160352 -0.25418044 -0.46161644]\n",
      "iteration #119: aTyK = 4.134195688716483 // a = [ 0.57830036 -0.84227218  2.57309261 -0.03792094 -0.38952994]\n",
      "iteration #120: aTyK = -0.41157143199779256 // a = [ 0.56418464 -0.92696647  2.54203804 -0.10849951 -0.41070351]\n",
      "iteration #121: aTyK = -0.7395724848910445 // a = [ 0.54678892 -1.04699697  2.48637172 -0.20765514 -0.45071368]\n",
      "iteration #122: aTyK = 0.2734908223827546 // a = [ 0.53952383 -1.08768148  2.46602946 -0.24325409 -0.46524386]\n",
      "iteration #123: aTyK = 3.491031203341672 // a = [ 0.56443414 -0.89587208  2.53577834 -0.076355   -0.41542324]\n",
      "iteration #124: aTyK = -0.6451402316891865 // a = [ 0.54798274 -0.99951591  2.49135955 -0.15696687 -0.44503576]\n",
      "iteration #125: aTyK = -0.24342637595778438 // a = [ 0.53554847 -1.08282548  2.45032648 -0.22784217 -0.47114772]\n",
      "iteration #126: aTyK = 1.6348691783144638 // a = [ 0.54189717 -1.0371149   2.47064229 -0.18975002 -0.45972007]\n",
      "iteration #127: aTyK = 0.7087130261448378 // a = [ 0.5389843  -1.05517469  2.46248626 -0.2037318  -0.46496324]\n",
      "iteration #128: aTyK = 0.3453421828780474 // a = [ 0.53243772 -1.09510882  2.44284652 -0.23581003 -0.47674708]\n",
      "iteration #129: aTyK = 1.9579934881017502 // a = [ 0.54201765 -1.03379724  2.46967034 -0.18216239 -0.45662921]\n",
      "iteration #130: aTyK = 1.2794600525998048 // a = [ 0.54481225 -1.01367611  2.47805414 -0.16595371 -0.45215785]\n",
      "iteration #131: aTyK = 1.8892569375071222 // a = [ 0.55370482 -0.9478711   2.50295334 -0.11170904 -0.43526197]\n",
      "iteration #132: aTyK = -0.9912840359252595 // a = [ 0.53379198 -1.10518254  2.42728454 -0.23915122 -0.47508765]\n",
      "iteration #133: aTyK = 2.127419183320118 // a = [ 0.54506617 -1.03302771  2.45885228 -0.17601574 -0.45028443]\n",
      "iteration #134: aTyK = 0.6513289423893989 // a = [ 0.54157946 -1.05499399  2.44908949 -0.19379797 -0.4555145 ]\n",
      "iteration #135: aTyK = 1.2492400819658327 // a = [ 0.54407186 -1.03979034  2.45556973 -0.17984052 -0.45202513]\n",
      "iteration #136: aTyK = 2.232289557115558 // a = [ 0.55639476 -0.94490405  2.49253842 -0.10467086 -0.42368248]\n",
      "iteration #137: aTyK = -1.4751351526112835 // a = [ 0.53164341 -1.10083756  2.40838383 -0.24327843 -0.48308572]\n",
      "iteration #138: aTyK = 1.2553127628365583 // a = [ 0.53419654 -1.08449754  2.41629852 -0.22923623 -0.47849009]\n",
      "iteration #139: aTyK = 0.6855092038510131 // a = [ 0.53105163 -1.10336699  2.4068638  -0.24433178 -0.48415092]\n",
      "iteration #140: aTyK = 1.9570114107764667 // a = [ 0.54062174 -1.0373332   2.43653115 -0.19265317 -0.46405368]\n",
      "iteration #141: aTyK = 1.048850734624291 // a = [ 0.54111025 -1.0340602   2.43804552 -0.18991753 -0.46288127]\n",
      "iteration #142: aTyK = 1.069170335507212 // a = [ 0.54180195 -1.02928745  2.4401898  -0.18638984 -0.46129035]\n",
      "iteration #143: aTyK = 0.6665926366291401 // a = [ 0.53846788 -1.04862508  2.4311878  -0.20339361 -0.46762509]\n",
      "iteration #144: aTyK = 1.0879417081412717 // a = [ 0.5393473  -1.04264504  2.43400194 -0.19820505 -0.46560243]\n",
      "iteration #145: aTyK = 0.7079429662040306 // a = [ 0.53642673 -1.06221286  2.42436406 -0.2148523  -0.47290385]\n",
      "iteration #146: aTyK = 1.5122181388533917 // a = [ 0.54154891 -1.02789425  2.4397306  -0.18821696 -0.46112284]\n",
      "iteration #147: aTyK = 1.6520765522652328 // a = [ 0.54806967 -0.98681343  2.45603252 -0.15561313 -0.44873338]\n",
      "iteration #148: aTyK = 0.20477510947975297 // a = [ 0.54011742 -1.03850304  2.43217577 -0.19696483 -0.46463788]\n",
      "iteration #149: aTyK = -0.2385189698384096 // a = [ 0.52773223 -1.11529122  2.39006612 -0.26384485 -0.49312382]\n",
      "iteration #150: aTyK = 1.1155192091165258 // a = [ 0.52888743 -1.10847559  2.3935317  -0.25795337 -0.49104447]\n",
      "Epoch #1: \n",
      "last a: [ 0.52773223 -1.11529122  2.39006612 -0.26384485 -0.49312382]\n",
      "new a: [ 0.52888743 -1.10847559  2.3935317  -0.25795337 -0.49104447]\n",
      "iteration #151: aTyK = 2.7936792700954562 // a = [ 0.51095063 -1.19995323  2.33075293 -0.28306488 -0.49463183]\n",
      "iteration #152: aTyK = 1.1282213862509627 // a = [ 0.50966842 -1.20623608  2.32690628 -0.28485998 -0.49488827]\n",
      "iteration #153: aTyK = 1.817163335465982 // a = [ 0.50149679 -1.24464275  2.30075706 -0.29548311 -0.4965226 ]\n",
      "iteration #154: aTyK = 1.3659578186267591 // a = [ 0.49783721 -1.26147681  2.28941236 -0.30097247 -0.49725452]\n",
      "iteration #155: aTyK = 1.9115252899665025 // a = [ 0.48872196 -1.30705308  2.25659745 -0.31373383 -0.49907757]\n",
      "iteration #156: aTyK = 1.4983868752193903 // a = [ 0.48373809 -1.33396597  2.23716037 -0.3222064  -0.50107111]\n",
      "iteration #157: aTyK = 1.352429574791743 // a = [ 0.48021379 -1.35017773  2.22517776 -0.32714042 -0.5021284 ]\n",
      "iteration #158: aTyK = 0.7037932224842285 // a = [ 0.48317586 -1.33536739  2.23524879 -0.32269732 -0.50153599]\n",
      "iteration #159: aTyK = 0.5376973937341987 // a = [ 0.48779888 -1.31502608  2.24865557 -0.31622508 -0.50061138]\n",
      "iteration #160: aTyK = 0.4906046113971376 // a = [ 0.49289284 -1.2900657   2.26444682 -0.30858415 -0.50010199]\n",
      "iteration #161: aTyK = 1.3420946752480774 // a = [ 0.48947189 -1.30853881  2.25178932 -0.31371557 -0.50078618]\n",
      "iteration #162: aTyK = 1.262467127632089 // a = [ 0.48684722 -1.32113724  2.24286544 -0.31791504 -0.50131111]\n",
      "iteration #163: aTyK = 0.3787726291605482 // a = [ 0.49305949 -1.29131832  2.26150226 -0.30921786 -0.50068988]\n",
      "iteration #164: aTyK = 1.3346888509775887 // a = [ 0.48971261 -1.30570994  2.25146159 -0.31289944 -0.50102457]\n",
      "iteration #165: aTyK = 1.4467570714156501 // a = [ 0.48524503 -1.33162185  2.23359131 -0.31826052 -0.50191809]\n",
      "iteration #166: aTyK = 2.0446442217016054 // a = [ 0.47479859 -1.39116657  2.18762697 -0.33393019 -0.50609666]\n",
      "iteration #167: aTyK = 0.8576963513036056 // a = [ 0.47622163 -1.38348218  2.19317681 -0.33208024 -0.50552745]\n",
      "iteration #168: aTyK = 0.4800107853915945 // a = [ 0.48142152 -1.35696273  2.21137643 -0.32480039 -0.50396748]\n",
      "iteration #169: aTyK = 0.44661350611488615 // a = [ 0.48695539 -1.3254197   2.23240512 -0.31539282 -0.50230732]\n",
      "iteration #170: aTyK = 1.5866729520463903 // a = [ 0.48108866 -1.35534002  2.21011154 -0.32419291 -0.50406734]\n",
      "iteration #171: aTyK = 0.02469039467755163 // a = [ 0.49084175 -1.3026733   2.24327207 -0.30761265 -0.50211672]\n",
      "iteration #172: aTyK = 1.4850489300700147 // a = [ 0.48599126 -1.32741079  2.22532526 -0.31488838 -0.50405692]\n",
      "iteration #173: aTyK = 1.9753727825343024 // a = [ 0.47623754 -1.37227794  2.19021184 -0.32464211 -0.50600766]\n",
      "iteration #174: aTyK = -0.09957631579811643 // a = [ 0.4872333  -1.31619955  2.22649786 -0.30594931 -0.50050978]\n",
      "iteration #175: aTyK = 1.0581625269485304 // a = [ 0.48665167 -1.31899135  2.22452033 -0.3070544  -0.50062611]\n",
      "iteration #176: aTyK = -0.02615634804342548 // a = [ 0.49691324 -1.26768353  2.25530502 -0.2906359  -0.49857379]\n",
      "iteration #177: aTyK = 1.1620856895836509 // a = [ 0.49529238 -1.27578782  2.24979411 -0.29322927 -0.49922214]\n",
      "iteration #178: aTyK = 1.195786775602187 // a = [ 0.49333451 -1.28596873  2.24294157 -0.29616607 -0.49961371]\n",
      "iteration #179: aTyK = 0.9177432165045953 // a = [ 0.49415708 -1.28169138  2.2457383  -0.29501448 -0.4994492 ]\n",
      "iteration #180: aTyK = 1.0846571711817665 // a = [ 0.49331051 -1.28567027  2.24302927 -0.29636899 -0.49961851]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration #181: aTyK = 0.7013698956061605 // a = [ 0.49629681 -1.27133602  2.25228681 -0.29159091 -0.49902125]\n",
      "iteration #182: aTyK = 0.6518625795404756 // a = [ 0.49977818 -1.2525366   2.26412348 -0.28636885 -0.4976287 ]\n",
      "iteration #183: aTyK = 2.790177989428461 // a = [ 0.4818764  -1.34562585  2.19072618 -0.31322152 -0.49941888]\n",
      "iteration #184: aTyK = 1.7435902643884775 // a = [ 0.4744405  -1.38652332  2.15949539 -0.32363178 -0.50090606]\n",
      "iteration #185: aTyK = -0.21071693820545878 // a = [ 0.48654767 -1.32719819  2.19702762 -0.30547103 -0.49848463]\n",
      "iteration #186: aTyK = 0.41478293509830877 // a = [ 0.49239984 -1.29793734  2.21575456 -0.29844842 -0.49731419]\n",
      "iteration #187: aTyK = 0.6214396701369127 // a = [ 0.49618544 -1.27711652  2.22900417 -0.29352714 -0.49655707]\n",
      "iteration #188: aTyK = 1.8021358287318332 // a = [ 0.48816409 -1.31642117  2.20012728 -0.30475704 -0.49735921]\n",
      "iteration #189: aTyK = 0.8006367785911745 // a = [ 0.49015772 -1.30764919  2.20610818 -0.30216532 -0.49696048]\n",
      "iteration #190: aTyK = 0.7692745780873995 // a = [ 0.49246497 -1.2958822   2.21395285 -0.29870444 -0.49649903]\n",
      "iteration #191: aTyK = 1.2246234742792943 // a = [ 0.49021874 -1.30711337  2.20609102 -0.30162454 -0.4971729 ]\n",
      "iteration #192: aTyK = -0.8590458461487289 // a = [ 0.5088092  -1.22345631  2.24884908 -0.27745695 -0.49159576]\n",
      "iteration #193: aTyK = 1.8629053145688115 // a = [ 0.50018014 -1.26142414  2.22123611 -0.28867472 -0.49332157]\n",
      "iteration #194: aTyK = 1.2095133305402799 // a = [ 0.49808501 -1.27189981  2.21390314 -0.29202693 -0.49457865]\n",
      "iteration #195: aTyK = 1.6715453057431855 // a = [ 0.49136956 -1.30614862  2.18838442 -0.30478629 -0.49726483]\n",
      "iteration #196: aTyK = 0.21112919660723595 // a = [ 0.49925826 -1.26828282  2.21205054 -0.2937421  -0.49489822]\n",
      "iteration #197: aTyK = 1.86784095333942 // a = [ 0.49057986 -1.31254271  2.17907259 -0.30762755 -0.4966339 ]\n",
      "iteration #198: aTyK = 0.8959103253398562 // a = [ 0.49162075 -1.30775458  2.18240346 -0.3061703  -0.49642572]\n",
      "iteration #199: aTyK = 1.0768736646183292 // a = [ 0.49085202 -1.31182889  2.17955913 -0.3073234  -0.49657947]\n",
      "iteration #200: aTyK = 0.594684057651139 // a = [ 0.49490517 -1.29156309  2.19293456 -0.30164898 -0.49576884]\n",
      "iteration #201: aTyK = 3.640472452112644 // a = [ 0.5213099  -1.10673002  2.27742968 -0.17754678 -0.45880223]\n",
      "iteration #202: aTyK = 0.7611510790511096 // a = [ 0.51892141 -1.12201635  2.26978651 -0.18829498 -0.46238496]\n",
      "iteration #203: aTyK = 1.80287603926313 // a = [ 0.52695017 -1.0666179   2.29467567 -0.14895405 -0.45034182]\n",
      "iteration #204: aTyK = 1.2429548231203889 // a = [ 0.52937972 -1.05325539  2.30026363 -0.13923586 -0.44718341]\n",
      "iteration #205: aTyK = 1.187302190928916 // a = [ 0.53125274 -1.04108074  2.30550809 -0.13061996 -0.44437387]\n",
      "iteration #206: aTyK = 0.11296069296871103 // a = [ 0.52238235 -1.09164198  2.28067099 -0.17053673 -0.45590538]\n",
      "iteration #207: aTyK = 0.3597191190403901 // a = [ 0.51597954 -1.13197968  2.25954172 -0.20062993 -0.46614988]\n",
      "iteration #208: aTyK = 0.7360494048986936 // a = [ 0.51334003 -1.14491326  2.25320691 -0.2093403  -0.46878938]\n",
      "iteration #209: aTyK = 2.0811790184971803 // a = [ 0.52415182 -1.07355544  2.2845611  -0.15960606 -0.45473406]\n",
      "iteration #210: aTyK = 0.1491128463434075 // a = [ 0.51564295 -1.11780158  2.26158714 -0.19279066 -0.46664648]\n",
      "iteration #211: aTyK = 1.6916044325523831 // a = [ 0.522559   -1.08322135  2.27541923 -0.16858451 -0.45973043]\n",
      "iteration #212: aTyK = 0.43983987212053055 // a = [ 0.51695739 -1.1162708   2.25861443 -0.19211123 -0.46813283]\n",
      "iteration #213: aTyK = 2.448293434910135 // a = [ 0.53144033 -1.0293732   2.29047689 -0.13417949 -0.4536499 ]\n",
      "iteration #214: aTyK = 0.37110668416093073 // a = [ 0.5251514  -1.06773569  2.27223898 -0.16373748 -0.46245441]\n",
      "iteration #215: aTyK = 0.05532107731506741 // a = [ 0.51570461 -1.12063771  2.24484329 -0.19774592 -0.47473523]\n",
      "iteration #216: aTyK = 1.5682652173887872 // a = [ 0.52138726 -1.08256394  2.26245951 -0.17274225 -0.46677952]\n",
      "iteration #217: aTyK = 0.23110167366034418 // a = [ 0.51369828 -1.12562224  2.23939256 -0.20734268 -0.47831299]\n",
      "iteration #218: aTyK = 1.2969687943997252 // a = [ 0.51666796 -1.10839805  2.24741072 -0.19516696 -0.47534331]\n",
      "iteration #219: aTyK = 3.0023626539818453 // a = [ 0.53669159 -0.98425157  2.2914627  -0.10506064 -0.44530787]\n",
      "iteration #220: aTyK = 0.14603559355080176 // a = [ 0.52815195 -1.03207358  2.27011359 -0.13836525 -0.45470148]\n",
      "iteration #221: aTyK = -0.220665475573961 // a = [ 0.51594529 -1.10409284  2.23105229 -0.19695719 -0.47667345]\n",
      "iteration #222: aTyK = 1.3795788678209586 // a = [ 0.51974108 -1.08093853  2.2416805  -0.18177404 -0.47173893]\n",
      "iteration #223: aTyK = 2.284271572206676 // a = [ 0.5325838  -1.00002942  2.27378729 -0.11884473 -0.45247486]\n",
      "iteration #224: aTyK = 0.30253130791308447 // a = [ 0.52560911 -1.04257501  2.25425817 -0.15162576 -0.46084448]\n",
      "iteration #225: aTyK = 0.8606108548584732 // a = [ 0.52421522 -1.05149592  2.25021588 -0.15761949 -0.46265654]\n",
      "iteration #226: aTyK = 1.0062550946147981 // a = [ 0.52427777 -1.05108308  2.25040353 -0.15734427 -0.46256897]\n",
      "iteration #227: aTyK = 1.7248063093416341 // a = [ 0.53152583 -1.00179625  2.27069811 -0.12255356 -0.45242168]\n",
      "iteration #228: aTyK = 0.7502993860623901 // a = [ 0.52902882 -1.01852619  2.26320709 -0.1350386  -0.45666659]\n",
      "iteration #229: aTyK = 0.3115013144220029 // a = [ 0.52214384 -1.05983611  2.24324063 -0.16602104 -0.46699407]\n",
      "iteration #230: aTyK = 0.734564056772542 // a = [ 0.51948948 -1.07496596  2.2363393  -0.17531129 -0.46964843]\n",
      "iteration #231: aTyK = 1.2084051845011654 // a = [ 0.52157353 -1.06350368  2.24134102 -0.1673919  -0.46735597]\n",
      "iteration #232: aTyK = 1.0351842274785783 // a = [ 0.52192537 -1.06156854  2.24218544 -0.16609008 -0.46700413]\n",
      "iteration #233: aTyK = 0.7894277542292141 // a = [ 0.51981965 -1.07378173  2.23649999 -0.1743024  -0.469531  ]\n",
      "iteration #234: aTyK = 1.5245125987933479 // a = [ 0.52506478 -1.04231098  2.25066183 -0.14755226 -0.46113879]\n",
      "iteration #235: aTyK = -0.2928776496100882 // a = [ 0.512136   -1.11212637  2.2118755  -0.20573175 -0.48053196]\n",
      "iteration #236: aTyK = 0.3348895266812386 // a = [ 0.5054849  -1.152033    2.18926175 -0.23566172 -0.49117373]\n",
      "iteration #237: aTyK = 2.270795466230065 // a = [ 0.51819285 -1.0668897   2.22865641 -0.17593433 -0.4721118 ]\n",
      "iteration #238: aTyK = 2.465158949972059 // a = [ 0.53284444 -0.97458469  2.26235506 -0.11146734 -0.45306473]\n",
      "iteration #239: aTyK = -0.816235121628198 // a = [ 0.51468209 -1.07629386  2.20786801 -0.18593298 -0.47667579]\n",
      "iteration #240: aTyK = 1.248674542421579 // a = [ 0.51716883 -1.06261676  2.21408487 -0.175986   -0.47344302]\n",
      "iteration #241: aTyK = 0.9130726731644669 // a = [ 0.51629956 -1.06739776  2.21182476 -0.1798108  -0.47448614]\n",
      "iteration #242: aTyK = 0.8507627742303638 // a = [ 0.51480719 -1.07650123  2.20734764 -0.18667571 -0.47657547]\n",
      "iteration #243: aTyK = 1.308389482645664 // a = [ 0.51789108 -1.05861464  2.21536577 -0.17434013 -0.47287479]\n",
      "iteration #244: aTyK = 0.7280380781745528 // a = [ 0.51517146 -1.07221274  2.20911065 -0.18331488 -0.47559441]\n",
      "iteration #245: aTyK = 0.9128163320475169 // a = [ 0.51429963 -1.07709502  2.20675669 -0.18697659 -0.4767278 ]\n",
      "iteration #246: aTyK = 0.3622469754841875 // a = [ 0.5079221  -1.11344694  2.1876241  -0.21376222 -0.48438083]\n",
      "iteration #247: aTyK = 1.0221120058189141 // a = [ 0.50814322 -1.11218656  2.18826534 -0.21283351 -0.48409338]\n",
      "iteration #248: aTyK = 1.5859494557789828 // a = [ 0.51400271 -1.07585769  2.20525788 -0.18763769 -0.47647604]\n",
      "iteration #249: aTyK = 0.5467635289026811 // a = [ 0.50947035 -1.09897275  2.19392697 -0.20123478 -0.48146164]\n",
      "iteration #250: aTyK = 1.0626415721161022 // a = [ 0.51009676 -1.09540218  2.19568093 -0.19866648 -0.4806473 ]\n",
      "iteration #251: aTyK = 1.5388070270541192 // a = [ 0.51548483 -1.06145734  2.21346156 -0.16633806 -0.46717712]\n",
      "iteration #252: aTyK = 1.4005821382549568 // a = [ 0.51949065 -1.03822358  2.22427728 -0.14590837 -0.45956606]\n",
      "iteration #253: aTyK = 2.0050129893999813 // a = [ 0.52954078 -0.96686765  2.25442767 -0.0866126  -0.43846079]\n",
      "iteration #254: aTyK = 0.2981451751066597 // a = [ 0.52252224 -1.01108451  2.23407388 -0.12591647 -0.45109417]\n",
      "iteration #255: aTyK = 1.0700281410322026 // a = [ 0.52322252 -1.00653268  2.23617472 -0.12185484 -0.44955356]\n",
      "iteration #256: aTyK = 2.1662060711879105 // a = [ 0.53488458 -0.91790102  2.27116091 -0.04488524 -0.42506323]\n",
      "iteration #257: aTyK = -0.7904808002810508 // a = [ 0.51697977 -1.00563458  2.22639889 -0.12545687 -0.4555014 ]\n",
      "iteration #258: aTyK = 1.9778766983349847 // a = [ 0.52675854 -0.93424958  2.25475731 -0.06385064 -0.43789962]\n",
      "iteration #259: aTyK = 1.2543733985918148 // a = [ 0.52930227 -0.91720656  2.26111665 -0.04909698 -0.4333209 ]\n",
      "iteration #260: aTyK = -0.6826411063168454 // a = [ 0.51247586 -1.03835672  2.20054157 -0.15173809 -0.47538693]\n",
      "iteration #261: aTyK = 0.9197479331679865 // a = [ 0.51167334 -1.0435731   2.1979735  -0.15583095 -0.47699197]\n",
      "iteration #262: aTyK = 1.9648548412861047 // a = [ 0.52132189 -0.98182239  2.22402458 -0.10469364 -0.45865973]\n",
      "iteration #263: aTyK = 1.0219971043397473 // a = [ 0.52154186 -0.98032659  2.22468449 -0.1034838  -0.45819779]\n",
      "iteration #264: aTyK = 0.9384230540017509 // a = [ 0.52092609 -0.98383648  2.22314507 -0.10656265 -0.45942933]\n",
      "iteration #265: aTyK = 0.606619168575703 // a = [ 0.51699228 -1.00665257  2.21213041 -0.12662507 -0.46887047]\n",
      "iteration #266: aTyK = 0.5962817798138449 // a = [ 0.5129551  -1.03249053  2.19921142 -0.14802214 -0.47815599]\n",
      "iteration #267: aTyK = 1.275401605093256 // a = [ 0.51570911 -1.01458943  2.20747347 -0.13287505 -0.47319876]\n",
      "iteration #268: aTyK = 0.8395303633419351 // a = [ 0.51410442 -1.02694559  2.20137563 -0.14362651 -0.47672909]\n",
      "iteration #269: aTyK = 3.7572998358264247 // a = [ 0.54167742 -0.8146335   2.27306542  0.04662718 -0.41331119]\n",
      "iteration #270: aTyK = -0.2677894220112549 // a = [ 0.52899952 -0.89070087  2.24517405 -0.0167623  -0.43232803]\n",
      "iteration #271: aTyK = -0.47782095055731943 // a = [ 0.51422131 -0.99267051  2.19788378 -0.10099809 -0.46631792]\n",
      "iteration #272: aTyK = 0.31818543441038116 // a = [ 0.50740317 -1.03085213  2.17879298 -0.134407   -0.47995421]\n",
      "iteration #273: aTyK = 3.18997322573021 // a = [ 0.5293029  -0.86222419  2.24011223  0.0123212  -0.43615474]\n",
      "iteration #274: aTyK = -0.42088887009726683 // a = [ 0.51509401 -0.95174019  2.20174823 -0.05730235 -0.46173074]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration #275: aTyK = -0.10794592973255224 // a = [ 0.50401455 -1.02597257  2.16518601 -0.12045527 -0.48499761]\n",
      "iteration #276: aTyK = 1.550120000600904 // a = [ 0.50951575 -0.98636393  2.18278985 -0.08744807 -0.47509545]\n",
      "iteration #277: aTyK = 0.7690515464925545 // a = [ 0.50720627 -1.00068273  2.17632329 -0.0985336  -0.47925252]\n",
      "iteration #278: aTyK = 0.413457656451202 // a = [ 0.50134084 -1.03646181  2.15872702 -0.12727417 -0.48981028]\n",
      "iteration #279: aTyK = 1.828916037832811 // a = [ 0.50963    -0.98341119  2.18193667 -0.08085487 -0.47240304]\n",
      "iteration #280: aTyK = 1.2499236516596444 // a = [ 0.51212924 -0.96541668  2.18943438 -0.0663593  -0.46840427]\n",
      "iteration #281: aTyK = 1.7962977867795331 // a = [ 0.52009222 -0.90649065  2.21173072 -0.01778514 -0.45327461]\n",
      "iteration #282: aTyK = -0.7430187578954657 // a = [ 0.50266203 -1.04418913  2.14549601 -0.12933834 -0.48813498]\n",
      "iteration #283: aTyK = 1.9709512200818864 // a = [ 0.51237154 -0.98204825  2.17268264 -0.07496507 -0.46677406]\n",
      "iteration #284: aTyK = 0.6735039727202787 // a = [ 0.50910658 -1.0026175   2.16354075 -0.09161637 -0.4716715 ]\n",
      "iteration #285: aTyK = 1.1550459553926329 // a = [ 0.51065704 -0.9931597   2.16757195 -0.08293379 -0.46950085]\n",
      "iteration #286: aTyK = 2.2197048778757997 // a = [ 0.52285409 -0.89924242  2.20416309 -0.00853179 -0.44144764]\n",
      "iteration #287: aTyK = -1.2445289674564695 // a = [ 0.5004088  -1.04064775  2.12784911 -0.13422542 -0.49531634]\n",
      "iteration #288: aTyK = 1.19321373530581 // a = [ 0.50234094 -1.02828207  2.13383874 -0.12359866 -0.49183849]\n",
      "iteration #289: aTyK = 0.7444181157832022 // a = [ 0.49978512 -1.04361698  2.12617128 -0.13586659 -0.49643896]\n",
      "iteration #290: aTyK = 1.8862425005537018 // a = [ 0.50864754 -0.98246625  2.1536448  -0.0880095  -0.47782787]\n",
      "iteration #291: aTyK = 1.037217519765023 // a = [ 0.50901972 -0.97997268  2.15479854 -0.08592531 -0.47693465]\n",
      "iteration #292: aTyK = 1.1080850655174102 // a = [ 0.51010057 -0.97251481  2.15814918 -0.08041298 -0.47444869]\n",
      "iteration #293: aTyK = 0.6150412222238923 // a = [ 0.50625098 -0.99484241  2.14775529 -0.10004587 -0.48176291]\n",
      "iteration #294: aTyK = 1.0841858608986819 // a = [ 0.50709284 -0.98911778  2.15044924 -0.09507891 -0.47982664]\n",
      "iteration #295: aTyK = 0.7650301417949015 // a = [ 0.50474314 -1.00486076  2.14269523 -0.10847219 -0.48570088]\n",
      "iteration #296: aTyK = 1.4809056484440406 // a = [ 0.5095522  -0.97264008  2.1571224  -0.0834651  -0.47464005]\n",
      "iteration #297: aTyK = 1.5444158713567742 // a = [ 0.51499636 -0.93834188  2.1707328  -0.0562443  -0.46429615]\n",
      "iteration #298: aTyK = 0.2930901326863129 // a = [ 0.50792726 -0.98429102  2.1495255  -0.09300362 -0.47843435]\n",
      "iteration #299: aTyK = -0.11109111817055872 // a = [ 0.49681635 -1.05317867  2.1117484  -0.15300254 -0.50398944]\n",
      "iteration #300: aTyK = 1.069186520748901 // a = [ 0.49750821 -1.04909666  2.113824   -0.14947402 -0.50274409]\n",
      "Epoch #2: \n",
      "last a: [ 0.49681635 -1.05317867  2.1117484  -0.15300254 -0.50398944]\n",
      "new a: [ 0.49750821 -1.04909666  2.113824   -0.14947402 -0.50274409]\n",
      "aT: [ 0.49750821 -1.04909666  2.113824   -0.14947402 -0.50274409]\n"
     ]
    }
   ],
   "source": [
    "# We already have all our data points with its correct label and with the sample normalisation alreay done, let's apply the \n",
    "# Widrow-Hoff Learning algorithm:\n",
    "\n",
    "# We initialise the values:\n",
    "eta = 0.01 # Learning rate of 0.01\n",
    "b = np.array([1]*150) # All values of b are equal to 1\n",
    "a = np.array([0.5, -1.5, 2.5, -0.5, -0.5]) # Inital values of a=(w0, wT)\n",
    "\n",
    "# We estimate the new vector\n",
    "new_a2 = widrow(n=150, data=data, epochs=2, a=a, b=b, eta=eta)\n",
    "\n",
    "print(\"aT: {}\".format(new_a2)) # It should be [0.49750821, -1.04909666, 2.113824, -0.14947402, -0.50274409]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1 score: 50\n",
      "Class -1 score: 100\n",
      "Total correctly predicted instances: 150\n",
      "Percentage of correct instances: 100.0\n"
     ]
    }
   ],
   "source": [
    "# We already have our classification decision boundary. It's the plane that divides the feature space in two and it has this\n",
    "# norm [0.49750821 -1.04909666  2.113824   -0.14947402 -0.50274409]\n",
    "\n",
    "# What the second part of this coursework asks us is to reporte the percentage of correct outputs for both classes. So, \n",
    "# technically what we have to do is to multiply the data points to the equation and see if it's over or below zero\n",
    "\n",
    "# For datapoints from class 1:\n",
    "score = 0\n",
    "for i in range(50):\n",
    "    result = np.dot(new_a2, data.iloc[i])\n",
    "    if result > 0:\n",
    "        score +=1\n",
    "\n",
    "print(\"Class 1 score: {}\".format(score))\n",
    "total_score = score\n",
    "\n",
    "# For datapoints from the other class:\n",
    "# First we have to change the data set and put the points as they were before\n",
    "data.iloc[50:, 1:5] = -data.iloc[50:, 1:5]\n",
    "\n",
    "# Now we can apply the score:\n",
    "score = 0\n",
    "for i in range(50, 150):\n",
    "    result = np.dot(new_a2, data.iloc[i])\n",
    "    if result <= 0:\n",
    "        score +=1\n",
    "\n",
    "print(\"Class -1 score: {}\".format(score))\n",
    "total_score += score\n",
    "print(\"Total correctly predicted instances: {}\\nPercentage of correct instances: {}\".format(total_score, total_score*100/150))\n",
    "# It should be 100.0%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1 score: 44\n",
      "Class -1 score: 100\n",
      "Total correctly predicted instances: 144\n",
      "Percentage of correct instances: 96.0\n"
     ]
    }
   ],
   "source": [
    "# We can see that our classifier performed great for this division, now let's see the error rate of the first vector we had \n",
    "# before training: a = np.array([0.5, -1.5, 2.5, -0.5, -0.5])\n",
    "# For datapoints from class 1:\n",
    "first_a = np.array([0.5, -1.5, 2.5, -0.5, -0.5])\n",
    "\n",
    "score = 0\n",
    "for i in range(50):\n",
    "    result = np.dot(first_a, data.iloc[i])\n",
    "    if result > 0:\n",
    "        score +=1\n",
    "\n",
    "print(\"Class 1 score: {}\".format(score))\n",
    "total_score = score\n",
    "\n",
    "# For datapoints from the other class:\n",
    "# First we have to change the data set and put the points as they were before\n",
    "# data.iloc[50:, 1:5] = -data.iloc[50:, 1:5]. We don't have to this anymore because we already did it before\n",
    "\n",
    "# Now we can apply the score:\n",
    "score = 0\n",
    "for i in range(50, 150):\n",
    "    result = np.dot(first_a, data.iloc[i])\n",
    "    if result <= 0:\n",
    "        score +=1\n",
    "\n",
    "print(\"Class -1 score: {}\".format(score))\n",
    "total_score += score\n",
    "print(\"Total correctly predicted instances: {}\\nPercentage of correct instances: {}\".format(total_score, total_score*100/150))\n",
    "# It should be 96.0%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coursework 1 exercise 3\n",
    "\n",
    "# This exercise is a little bit different, it asks us to perfom a k-Nearest-Neighbour Classifier with k=1 and k=5 to the Iris\n",
    "# dataset to the 5 following datapoints:\n",
    "new_datapoints = pd.DataFrame([[7.0, 2.9, 6.3, 0.1],[7.8, 2.1, 1.7, 1.2], [6.5, 3.8, 1.1, 0.9], [6.4, 3.7, 3.0, 0.4], [4.8, 2.9, 5.3, 0.2]])\n",
    "\n",
    "# The exercise recommends us to use the data science package called scikit-learn, which provides \"KneighborsClassifier\" that\n",
    "# performs this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start by importing the requested library\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Now we initialise the model with k=1 first\n",
    "neigh1 = KNeighborsClassifier(n_neighbors=1, weights='distance')\n",
    "\n",
    "# Now we train our model with the data points from the Iris dataset\n",
    "neigh1.fit(iris.data, iris.target)\n",
    "\n",
    "# Now let's see where would this classifier locate the new datapoints\n",
    "neigh1.predict(new_datapoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's do the same but with k=5:\n",
    "neigh5 = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "\n",
    "# Now we train our model with the data points from the Iris dataset\n",
    "neigh5.fit(iris.data, iris.target)\n",
    "\n",
    "# Now let's see where would this classifier locate the new datapoints\n",
    "neigh5.predict(new_datapoints)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
